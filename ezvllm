#!/bin/bash

# 版本信息
VERSION="2.1.0"

# # 信号处理函数
# cleanup_monitor() {
#     if [[ -n "$MONITOR_PID" ]]; then
#         echo "正在清理超时监控进程 (PID: $MONITOR_PID)..."
#         kill "$MONITOR_PID" 2>/dev/null
#         wait "$MONITOR_PID" 2>/dev/null
#         echo "超时监控进程已清理"
        
#     fi
# }

# 修改 cleanup_monitor 函数
cleanup_monitor() {
    if [[ -n "$MONITOR_PID" && "$MONITOR_CLEANED" != "true" ]]; then
        echo "正在清理超时监控进程 (PID: $MONITOR_PID)..."
        kill "$MONITOR_PID" 2>/dev/null
        wait "$MONITOR_PID" 2>/dev/null
        echo "超时监控进程已清理"
        MONITOR_CLEANED="true"
    fi
}

# 设置信号陷阱
trap cleanup_monitor EXIT INT TERM

ENV_NAME="vllm"
GPU_ID="0"
MODEL_NAME="Qwen/Qwen3-4B"
API_KEY="1205"
PORT="8009"
MAX_MODEL_LEN="" 
GPU_UTIL="0.9"
DISABLE_FUNCTION_CALL=false
SYSTEM_PROMPT=""
USER_PROMPT=""
TEMPERATURE="0.7"
TIMEOUT_MINUTES="60"
SHOW_TIMEOUT_MINUTES=""
COMMAND=""
CONFIG_FILE="$HOME/.config/ezvllm/config"

# 自动选择GPU函数
auto_select_gpu() {
  # 检查nvidia-smi是否可用
  if ! command -v nvidia-smi >/dev/null 2>&1; then
    echo "错误: nvidia-smi 不可用，无法检测GPU状态" >&2
    echo "使用默认GPU: 0" >&2
    echo "0"
    return
  fi
  
  # 获取GPU数量
  gpu_count=$(nvidia-smi --list-gpus 2>/dev/null | wc -l)
  if [ "$gpu_count" -eq 0 ]; then
    echo "错误: 未检测到GPU" >&2
    echo "使用默认GPU: 0" >&2
    echo "0"
    return
  fi
  
  echo "正在检测可用GPU..." >&2
  echo "检测到 $gpu_count 张GPU" >&2
  
  # 检查每张GPU的使用率
  best_gpu=""
  best_util=100
  
  for ((i=0; i<gpu_count; i++)); do
    # 获取GPU利用率
    util=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits --id=$i 2>/dev/null)
    
    # 获取显存使用率
    memory_util=$(nvidia-smi --query-gpu=utilization.memory --format=csv,noheader,nounits --id=$i 2>/dev/null)
    
    # 获取显存使用情况
    memory_info=$(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits --id=$i 2>/dev/null)
    memory_used=$(echo "$memory_info" | cut -d',' -f1 | tr -d ' ')
    memory_total=$(echo "$memory_info" | cut -d',' -f2 | tr -d ' ')
    
    if [ -n "$util" ] && [ -n "$memory_util" ]; then
      # 计算显存使用百分比
      if [ "$memory_total" -gt 0 ]; then
        memory_percent=$((memory_used * 100 / memory_total))
      else
        memory_percent=0
      fi
      
      echo "GPU $i: 计算利用率=${util}%, 显存利用率=${memory_util}%, 显存使用=${memory_used}MB/${memory_total}MB (${memory_percent}%)" >&2
      
      # 选择GPU利用率和显存利用率都小于5%的GPU
      if [ "$util" -lt 5 ] && [ "$memory_util" -lt 5 ] && [ "$memory_percent" -lt 5 ]; then
        if [ -z "$best_gpu" ] || [ "$util" -lt "$best_util" ] || ([ "$util" -eq "$best_util" ] && [ "$i" -lt "$best_gpu" ]); then
          best_gpu="$i"
          best_util="$util"
        fi
      fi
    else
      echo "GPU $i: 无法获取利用率信息" >&2
    fi
  done
  
  if [ -n "$best_gpu" ]; then
    echo "自动选择GPU: $best_gpu (利用率: ${best_util}%)" >&2
    echo "" >&2
    echo "$best_gpu"
    return 0
  else
    echo "错误: 没有找到利用率小于5%的GPU，请手动指定GPU或等待GPU空闲后重试" >&2
    echo "当前所有GPU状态如上所示" >&2
    return 1
  fi
}

# 加载配置文件函数
config_load() {
  if [ -f "$CONFIG_FILE" ]; then
    while IFS='=' read -r key value; do
      # 跳过注释和空行
      [[ $key =~ ^#.*$ || -z $key ]] && continue
      # 移除可能存在的引号
      value=$(echo "$value" | sed -e 's/^"//' -e 's/"$//' -e "s/^'//" -e "s/'$//")
      
      case "$key" in
        ENV_NAME) ENV_NAME="$value" ;;
        GPU_ID) GPU_ID="$value" ;;
        MODEL_NAME) MODEL_NAME="$value" ;;
        API_KEY) API_KEY="$value" ;;
        PORT) PORT="$value" ;;
        MAX_MODEL_LEN) MAX_MODEL_LEN="$value" ;;
        GPU_UTIL) GPU_UTIL="$value" ;;
        SYSTEM_PROMPT) SYSTEM_PROMPT="$value" ;;
        USER_PROMPT) USER_PROMPT="$value" ;;
        TEMPERATURE) TEMPERATURE="$value" ;;
        TIMEOUT_MINUTES) TIMEOUT_MINUTES="$value" ;;
        DISABLE_FUNCTION_CALL) 
          if [[ "$value" == "true" || "$value" == "1" || "$value" == "yes" ]]; then
            DISABLE_FUNCTION_CALL=true
          else
            DISABLE_FUNCTION_CALL=false
          fi
          ;;
      esac
    done < "$CONFIG_FILE"
    
  else
    echo "配置文件 $CONFIG_FILE 不存在，使用默认配置"
    mkdir -p "$(dirname "$CONFIG_FILE")" 2>/dev/null
    if [ $? -eq 0 ]; then
      echo "# ezvllm 默认配置文件" > "$CONFIG_FILE"
      echo "ENV_NAME=$ENV_NAME" >> "$CONFIG_FILE"
      echo "GPU_ID=$GPU_ID" >> "$CONFIG_FILE"
      echo "MODEL_NAME=$MODEL_NAME" >> "$CONFIG_FILE"
      echo "API_KEY=$API_KEY" >> "$CONFIG_FILE"
      echo "PORT=$PORT" >> "$CONFIG_FILE"
      echo "MAX_MODEL_LEN=$MAX_MODEL_LEN" >> "$CONFIG_FILE"
      echo "GPU_UTIL=$GPU_UTIL" >> "$CONFIG_FILE"
      echo "DISABLE_FUNCTION_CALL=$DISABLE_FUNCTION_CALL" >> "$CONFIG_FILE"
      echo "SYSTEM_PROMPT=$SYSTEM_PROMPT" >> "$CONFIG_FILE"
      echo "USER_PROMPT=$USER_PROMPT" >> "$CONFIG_FILE"
      echo "TEMPERATURE=$TEMPERATURE" >> "$CONFIG_FILE"
      echo "TIMEOUT_MINUTES=$TIMEOUT_MINUTES" >> "$CONFIG_FILE"
      echo "已创建默认配置文件: $CONFIG_FILE"
    fi
  fi
}



# 显示版本信息
show_version() {
  echo "ezvllm 版本 $VERSION"
  exit 0
}

# 显示主帮助信息
show_help() {
  echo "用法: ezvllm [命令] [选项]"
  echo "命令:"
  echo "  serve                    启动vllm服务（默认命令）"
  echo "  check                    检查指定端口上运行的模型"
  echo "  config                   管理配置文件"
  echo "  chat                     与模型进行交互式对话"
  echo "  help                     显示此帮助信息"
  echo ""
  echo "选项:"
  echo "  -v, --version            显示版本信息"
  echo "  -h, --help               显示此帮助信息"
  echo ""
  echo "运行 'ezvllm help <命令>' 查看特定命令的帮助信息"
  exit 0
}

# 显示serve命令帮助信息
show_serve_help() {
  echo "用法: ezvllm serve [选项]"
  echo "选项:"
  echo "  -e, --env-name NAME       指定conda环境名称 (默认: $ENV_NAME)"
  echo "  -g, --gpu-id ID           指定GPU ID (默认: $GPU_ID, 使用 'a' 或 'auto' 自动选择可用GPU)"
  echo "  -m, --model-name NAME     指定模型名称 (默认: $MODEL_NAME)"
  echo "  -k, --api-key KEY         指定API密钥 (默认: $API_KEY)"
  echo "  -p, --port PORT           指定端口号 (默认: $PORT)"
  echo "  -l, --max-model-len LEN   指定最大模型长度 (默认: ${MAX_MODEL_LEN:-不限制})"
  echo "  -u, --gpu-util UTIL       指定GPU使用率 (默认: $GPU_UTIL)"
  echo "  -d, --disable-function    禁用function call功能"
  echo "  -v, --vllm-args \"ARGS\"    传递额外参数给vllm serve命令（需要放在最后）"
  echo "  -h, --help                显示此帮助信息"
  echo "  -t, --timeout MINUTES     设置无响应退出时间（单位：分钟，默认: ${SHOW_TIMEOUT_MINUTES:- ∞ }分钟）"
  exit 0
}

# 显示check命令帮助信息
show_check_help() {
  echo "用法: ezvllm check [选项]"
  echo "选项:"
  echo "  -p, --port PORT           指定端口号 (默认: $PORT)"
  echo "  -k, --api-key KEY         指定API密钥 (默认: $API_KEY)"
  echo "  -h, --help                显示此帮助信息"
  echo "  -t, --test                测试API连接"
  echo "  -m, --model-name NAME     指定模型名称 (默认: $MODEL_NAME)"
  echo "  -i, --info                输出详细内容"
  exit 0
}

# 显示config命令帮助信息
show_config_help() {
  echo "用法: ezvllm config [选项]"
  echo "选项:"
  echo "  show                     显示当前配置"
  echo "  edit                     编辑配置文件"
  echo "  set KEY=VALUE            设置配置项"
  echo "  unset KEY                移除配置项"
  echo "  param                    显示所有可用的配置参数"
  echo "  -h, --help               显示此帮助信息"
  exit 0
}

# 显示 chat 命令帮助信息
show_chat_help() {
  echo "用法: ezvllm chat [选项]"
  echo "选项:"
  echo "  -m, --model-name NAME    指定模型名称 (默认: $MODEL_NAME)"
  echo "  -p, --port PORT          指定端口号 (默认: $PORT)"
  echo "  -k, --api-key KEY        指定API密钥 (默认: $API_KEY)"
  echo "  -s, --system TEXT        设置系统提示信息 (默认: ${SYSTEM_PROMPT:-无})"
  echo "  -u, --user TEXT          设置用户输入（默认：${USER_PROMPT:-无})"
  echo "  -t, --temperature VAL    设置温度参数 (默认: ${TEMPERATURE:-0.7})"
  echo "  -1, --single             单轮对话模式"
  echo "  -h, --help               显示此帮助信息"
  exit 0
}

# 加载配置文件
config_load

    
# 设置显示用的超时时间
if [[ -n "$TIMEOUT_MINUTES" && "$TIMEOUT_MINUTES" -gt 0 ]]; then
  SHOW_TIMEOUT_MINUTES="$TIMEOUT_MINUTES"
else
  SHOW_TIMEOUT_MINUTES=""
fi

if [[ $# -gt 0 ]]; then
  case "$1" in
    serve)
      COMMAND="serve"
      shift
      ;;
    check)
      COMMAND="check"
      shift
      ;;
    config)
      COMMAND="config"
      shift
      ;;
    chat)
      COMMAND="chat"
      shift
      ;;
    help)
      if [[ $# -eq 1 ]]; then
        show_help
      elif [[ "$2" == "serve" ]]; then
        show_serve_help
      elif [[ "$2" == "check" ]]; then
        show_check_help
      elif [[ "$2" == "config" ]]; then
        show_config_help
      elif [[ "$2" == "chat" ]]; then
        show_chat_help
      else
        echo "未知命令: $2"
        show_help
      fi
      ;;
    -v|--version)
      show_version
      ;;
    -h|--help)
      show_help
      ;;
    *)
      # 如果没有指定命令，默认为serve
      COMMAND="serve"
      ;;
  esac
else
  # 如果没有任何参数，默认为serve
  COMMAND="serve"
fi

case "$COMMAND" in
  serve)
    while [[ $# -gt 0 ]]; do
      case $1 in
        -e|--env-name)
          ENV_NAME="$2"
          shift 2
          ;;
        -g|--gpu-id)
          if [[ "$2" == "a" || "$2" == "auto" ]]; then
            GPU_ID="auto"
          else
            GPU_ID="$2"
          fi
          shift 2
          ;;
        -m|--model-name)
          MODEL_NAME="$2"
          shift 2
          ;;
        -k|--api-key)
          API_KEY="$2"
          shift 2
          ;;
        -p|--port)
          PORT="$2"
          shift 2
          ;;
        -l|--max-model-len)
          MAX_MODEL_LEN="$2"
          shift 2
          ;;
        -u|--gpu-util)
          GPU_UTIL="$2"
          shift 2
          ;;
        -d|--disable-function)
          DISABLE_FUNCTION_CALL=true
          shift
          ;;
        -t|--timeout)
          TIMEOUT_MINUTES="$2"
          shift 2
          ;;
        -v|--vllm-args)
          # 收集剩余所有参数作为VLLM参数
          shift
          VLLM_EXTRA_ARGS="$*"
          break
          ;;
        -h|--help)
          show_serve_help
          ;;
        *)
          echo "未知选项: $1"
          show_serve_help
          ;;
      esac
    done
    ;;
  check)
    TEST_MODE=false
    INFO_MODE=false
    while [[ $# -gt 0 ]]; do
      case $1 in
        -p|--port)
          PORT="$2"
          shift 2
          ;;
        -k|--api-key)
          API_KEY="$2"
          shift 2
          ;;
        -m|--model-name)
          MODEL_NAME="$2"
          shift 2
          ;;
        -t|--test)
          TEST_MODE=true
          shift
          ;;
        -h|--help)
          show_check_help
          ;;
        -i|--info)
          INFO_MODE=true
          shift
          ;;
        *)
          echo "未知选项: $1"
          show_check_help
          ;;
      esac
    done
    ;;
  config)
    while [[ $# -gt 0 ]]; do
      case $1 in
        show)
          echo "当前配置:"
          cat "$CONFIG_FILE"
          exit 0
          ;;
        edit)
          ${EDITOR:-vim} "$CONFIG_FILE"
          exit 0
          ;;
        set)
          if [[ $# -lt 2 ]]; then
            echo "用法: ezvllm config set KEY=VALUE"
            exit 1
          fi
          IFS='=' read -r key value <<< "$2"
          # 更新配置文件
          if [ -f "$CONFIG_FILE" ]; then
            if grep -q "^$key=" "$CONFIG_FILE"; then
              sed -i "s/^$key=.*/$key=$value/" "$CONFIG_FILE"
            else
              echo "$key=$value" >> "$CONFIG_FILE"
            fi
          else
            mkdir -p "$(dirname "$CONFIG_FILE")" 2>/dev/null
            echo "# ezvllm 默认配置文件" > "$CONFIG_FILE"
            echo "$key=$value" >> "$CONFIG_FILE"
          fi
          echo "已更新配置: $key=$value"
          exit 0
          ;;
        unset)
          # 移除配置项
          if [[ $# -lt 2 ]]; then
            echo "用法: ezvllm config unset KEY"
            exit 1
          fi
          key="$2"
          if [ ! -f "$CONFIG_FILE" ]; then
            echo "错误: 配置文件不存在"
            exit 1
          fi
          if grep -q "^$key=" "$CONFIG_FILE"; then
            sed -i "/^$key=/d" "$CONFIG_FILE"
            echo "已移除配置项: $key"
          else
            echo "配置项不存在: $key"
            exit 1
          fi
          exit 0
          ;;
        param)
          echo "可用的配置参数:"
          echo "  ENV_NAME              - Python虚拟环境名称 (默认: $ENV_NAME)"
          echo "  GPU_ID                - 使用的GPU ID (默认: $GPU_ID)"
          echo "  MODEL_NAME            - 模型名称 (默认: $MODEL_NAME)"
          echo "  API_KEY               - API密钥 (默认: $API_KEY)"
          echo "  PORT                  - 服务端口 (默认: $PORT)"
          echo "  MAX_MODEL_LEN         - 最大模型长度 (默认: 自动)"
          echo "  GPU_UTIL              - GPU利用率 (默认: $GPU_UTIL)"
          echo "  DISABLE_FUNCTION_CALL - 禁用函数调用 (默认: $DISABLE_FUNCTION_CALL)"
          echo "  SYSTEM_PROMPT         - 系统提示词 (默认: 空)"
          echo "  USER_PROMPT           - 用户输入提示 (默认: 空)"
          echo "  TEMPERATURE           - 生成温度 (默认: $TEMPERATURE)"
          echo "  TIMEOUT_MINUTES       - 超时时间（分钟） (默认: $TIMEOUT_MINUTES)"
          exit 0
          ;;
        -h|--help)
          show_config_help
          ;;
        *)
          echo "未知选项: $1"
          show_config_help
          ;;
      esac
    done
    ;;
  chat)
    SINGLE_MODE=false
    while [[ $# -gt 0 ]]; do
      case $1 in
        -m|--model-name)
          MODEL_NAME="$2"
          shift 2
          ;;
        -p|--port)
          PORT="$2"
          shift 2
          ;;
        -k|--api-key)
          API_KEY="$2"
          shift 2
          ;;
        -s|--system)
          SYSTEM_PROMPT="$2"
          shift 2
          ;;
        -t|--temperature)
          TEMPERATURE="$2"
          shift 2
          ;;
        -1|--single)
          SINGLE_MODE=true
          shift
          ;;
        -u|--user)
          USER_PROMPT="$2"
          shift 2
          ;;
        -h|--help)
          show_chat_help
          ;;
        *)
          echo "未知选项: $1"
          show_chat_help
          ;;
      esac
    done
    ;;
esac


check_running_model() {
  local port="$1"
  local api_key="$2"
  
  echo "正在检查端口 $port 上运行的 vllm 服务..."
  
  # 检查端口是否在监听
  if ! netstat -tuln | grep -q ":$port "; then
    echo "错误: 端口 $port 上没有运行服务"
    return 1
  fi
  
  echo "发送 API 请求到 http://localhost:$port..."
  model_info=$(curl -s -X GET "http://localhost:$port/v1/models" \
    -H "Authorization: Bearer $api_key" \
    -H "Content-Type: application/json")
  
  if [[ "$model_info" == *"error"* ]]; then
    echo "获取模型信息失败: $model_info"
    return 1
  else
    # 尝试提取模型名称
    model_name=$(echo "$model_info" | jq -r '.data[0].id' 2>/dev/null)
    
    if [ $? -eq 0 ] && [ -n "$model_name" ] && [ "$model_name" != "null" ]; then
      echo "当前运行的模型: $model_name"
      
      # 如果开启详细模式，则显示完整信息
      if [[ "$INFO_MODE" = true ]]; then
        echo "完整模型信息:"
        echo "$model_info" | jq '.'
      fi
    else
      echo "当前运行的模型信息:"
      echo "$model_info" | jq '.'
      
      # 如果没有jq，可以直接输出
      if [ $? -ne 0 ]; then
        echo "$model_info"
      fi
    fi
  fi
  
  # 获取进程信息
  if [[ "$INFO_MODE" = true ]]; then
    pid=$(lsof -i :$port -t)
    if [ -n "$pid" ]; then
      echo "进程信息:"
      ps -p "$pid" -o pid,cmd
    fi
  fi
}

# 测试API连接函数
test_api_connection() {
  local port="$1"
  local api_key="$2"
  
  echo "正在测试与端口 $port 上 vllm 服务的 $MODEL_NAME API 连接..."
  
  # 检查端口是否在监听
  if ! netstat -tuln | grep -q ":$port "; then
    echo "错误: 端口 $port 上没有运行服务"
    return 1
  fi
  
  # 尝试通过API发送简单的测试请求
  echo "发送测试请求到 http://localhost:$port..."
  
  response=$(curl -s -X POST "http://localhost:$port/v1/chat/completions" \
    -H "Authorization: Bearer $api_key" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "'"$MODEL_NAME"'",
      "messages": [{"role": "user", "content": "测试消息，请回复简短的确认"}],
      "max_tokens": 10
    }')
  
  if [[ "$response" == *"error"* ]]; then
    echo "API 连接测试失败: "
    if [[ "$INFO_MODE" = true ]]; then
      echo "$response" | jq '.'
      if [ $? -ne 0 ]; then
        echo "$response"
      fi
    fi
    return 1
  else
    echo "API 连接测试成功！"
    if [[ "$INFO_MODE" = true ]]; then
      echo "服务器响应:"
      echo "$response" | jq '.'
      if [ $? -ne 0 ]; then
        echo "$response"
      fi
    fi
    return 0
  fi
}

# 检测HTTP请求活动的辅助函数
check_http_activity() {
  local port="$1"
  local log_file="$2"
  
  # 方法1: 检查vllm的metrics端点
  if command -v curl >/dev/null 2>&1; then
    # 尝试访问metrics端点来触发连接检测
    response=$(curl -s -m 2 "http://localhost:${port}/metrics" 2>/dev/null || true)
    if [ -n "$response" ]; then
      echo "$(date '+%Y-%m-%d %H:%M:%S') - 通过metrics端点检测到服务活跃" >> "$log_file"
      return 0
    fi
  fi
  
  # 方法2: 检查TCP连接的统计信息
  if command -v ss >/dev/null 2>&1; then
    # 检查端口上的连接统计
    connections=$(ss -s 2>/dev/null | grep -E "(estab|listen)" || true)
    if [ -n "$connections" ]; then
      return 1  # 有连接但不确定是否为新请求
    fi
  fi
  
  return 1
}

# 超时监控函数
monitor_timeout() {
  local port="$1"
  local monitor_timeout_minutes="$2"
  local timeout_seconds=$((monitor_timeout_minutes * 60))
  local log_file="/tmp/ezvllm_timeout_${port}.log"
  local last_request_file="/tmp/ezvllm_last_request_${port}"
  local connections_log="/tmp/ezvllm_connections_${port}.log"
  
  echo "$(date '+%Y-%m-%d %H:%M:%S') - 开始监控端口 $port，超时时间: ${monitor_timeout_minutes}分钟" >> "$log_file"
  
  # 初始化最后请求时间为当前时间
  echo "$(date +%s)" > "$last_request_file"
  
  # 记录初始连接状态
  netstat -an | grep ":$port " > "$connections_log" 2>/dev/null || true
  
  while true; do
    sleep 10  # 每10秒检查一次，更频繁的检测
    
    # 检查vllm进程是否还在运行
    vllm_pid=$(pgrep -f "vllm.*serve.*--port $port" 2>/dev/null || true)
    if [ -z "$vllm_pid" ]; then
      echo "$(date '+%Y-%m-%d %H:%M:%S') - vllm进程已退出，停止监控" >> "$log_file"
      rm -f "$last_request_file" "$connections_log"
      break
    fi
    
    # 检查端口是否还在监听
    if ! ss -tuln 2>/dev/null | grep -q ":$port " && ! netstat -tuln 2>/dev/null | grep -q ":$port "; then
      echo "$(date '+%Y-%m-%d %H:%M:%S') - 端口 $port 已关闭，停止监控" >> "$log_file"
      rm -f "$last_request_file" "$connections_log"
      break
    fi
    
    current_time=$(date +%s)
    
    # 获取当前连接状态
    current_connections="/tmp/ezvllm_current_${port}.log"
    netstat -an 2>/dev/null | grep ":$port " > "$current_connections" || true
    
    # 检查是否有新的连接活动（比较连接状态的变化）
    if ! diff "$connections_log" "$current_connections" >/dev/null 2>&1; then
      # 连接状态有变化，说明可能有新请求
      echo "$current_time" > "$last_request_file"
      echo "$(date '+%Y-%m-%d %H:%M:%S') - 检测到连接状态变化，更新最后请求时间" >> "$log_file"
      cp "$current_connections" "$connections_log"
    fi
    
    # 检查是否有HTTP请求活动（通过检测端口上的数据传输）
    # 使用ss命令检查是否有数据在传输
    if command -v ss >/dev/null 2>&1; then
      data_transfer=$(ss -i | grep ":$port " | grep -E "(bytes_sent|bytes_received)" 2>/dev/null || true)
      if [ -n "$data_transfer" ]; then
        echo "$current_time" > "$last_request_file"
        echo "$(date '+%Y-%m-%d %H:%M:%S') - 检测到数据传输活动" >> "$log_file"
      fi
    fi
    
    # 检查超时
    if [ -f "$last_request_file" ]; then
      last_request_time=$(cat "$last_request_file")
      time_diff=$((current_time - last_request_time))
      
      if [ "$time_diff" -gt "$timeout_seconds" ]; then
        echo "$(date '+%Y-%m-%d %H:%M:%S') - 超时 ${monitor_timeout_minutes}分钟 无请求，准备关闭服务" >> "$log_file"
        
        # 查找并杀死vllm进程
        if [ -n "$vllm_pid" ]; then
          echo "$(date '+%Y-%m-%d %H:%M:%S') - 发送SIGTERM信号到进程 $vllm_pid" >> "$log_file"
          kill -TERM "$vllm_pid" 2>/dev/null || true
          
          # 等待10秒，如果进程还在运行则强制杀死
          sleep 10
          if kill -0 "$vllm_pid" 2>/dev/null; then
            echo "$(date '+%Y-%m-%d %H:%M:%S') - 强制杀死进程 $vllm_pid" >> "$log_file"
            kill -KILL "$vllm_pid" 2>/dev/null || true
          fi
        fi
        
        rm -f "$last_request_file" "$connections_log" "$current_connections"
        echo "$(date '+%Y-%m-%d %H:%M:%S') - 监控结束" >> "$log_file"
        break
      else
        remaining_time=$((timeout_seconds - time_diff))
        echo "$(date '+%Y-%m-%d %H:%M:%S') - 距离超时还有: $((remaining_time/60))分钟$((remaining_time%60))秒" >> "$log_file"
      fi
    fi
    
    rm -f "$current_connections"
  done
}

# 如果指定了check命令，则执行检查操作
if [ "$COMMAND" = "check" ]; then
  if [ "$TEST_MODE" = true ]; then
    test_api_connection "$PORT" "$API_KEY"
  else
    check_running_model "$PORT" "$API_KEY"
  fi
  exit $?
fi

# 如果指定了chat命令，则启动聊天
if [ "$COMMAND" = "chat" ]; then
  if ! netstat -tuln | grep -q ":$PORT "; then
    echo "错误: 端口 $PORT 上没有运行服务，请先启动服务"
    exit 1
  fi
  
  # 测试API连接
  echo "正在测试与模型的连接..."
  if ! test_api_connection "$PORT" "$API_KEY" > /dev/null; then
    echo "错误: 无法连接到模型API，请确保服务正常运行"
    exit 1
  fi
  
  # 初始化消息数组
  MESSAGES="[]"
  
  # 添加系统消息(如果提供)
  if [ -n "$SYSTEM_PROMPT" ]; then
    MESSAGES=$(echo "$MESSAGES" | jq --arg prompt "$SYSTEM_PROMPT" \
      '. + [{"role": "system", "content": $prompt}]')
  fi
  
  # 处理单轮对话模式 (-1/--single)
  if [ "$SINGLE_MODE" = true ]; then
    # 单轮对话模式
    if [ -n "$USER_PROMPT" ]; then
      # 如果设置了user_prompt，直接使用该值
      MESSAGES=$(echo "$MESSAGES" | jq --arg prompt "$USER_PROMPT" \
        '. + [{"role": "user", "content": $prompt}]')
    else
      # 如果没有设置user_prompt，让用户手动输入一次
      echo "请输入您的问题 (单轮对话模式)："
      echo -n "用户: "
      read -r USER_INPUT
      MESSAGES=$(echo "$MESSAGES" | jq --arg content "$USER_INPUT" \
        '. + [{"role": "user", "content": $content}]')
    fi
    
    # 发送请求到API
    echo "正在处理您的请求..."
    RESPONSE=$(curl -s -X POST "http://localhost:$PORT/v1/chat/completions" \
      -H "Authorization: Bearer $API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "'"$MODEL_NAME"'",
        "messages": '"$MESSAGES"',
        "temperature": '"$TEMPERATURE"'
      }')
    
    # 检查错误
    if [[ "$RESPONSE" == *"error"* || -z "$RESPONSE" ]]; then
      echo "错误: $(echo "$RESPONSE" | jq -r '.error.message // .error // "API请求失败"' 2>/dev/null || echo "$RESPONSE")"
      exit 1
    fi
    
    # 提取助手回复
    ASSISTANT_REPLY=$(echo "$RESPONSE" | jq -r '.choices[0].message.content' 2>/dev/null)
    
    # 显示助手回复
    echo -e "\n助手: $ASSISTANT_REPLY\n"
    
    # 单轮对话模式直接退出
    exit 0
  fi
  
  # 多轮对话模式
  if [ -n "$USER_PROMPT" ]; then
    MESSAGES=$(echo "$MESSAGES" | jq --arg prompt "$USER_PROMPT" \
      '. + [{"role": "user", "content": $prompt}]')
    
    echo "发送初始请求..."
    RESPONSE=$(curl -s -X POST "http://localhost:$PORT/v1/chat/completions" \
      -H "Authorization: Bearer $API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "'"$MODEL_NAME"'",
        "messages": '"$MESSAGES"',
        "temperature": '"$TEMPERATURE"'
      }')
    
    # 检查错误
    if [[ "$RESPONSE" == *"error"* || -z "$RESPONSE" ]]; then
      echo "错误: $(echo "$RESPONSE" | jq -r '.error.message // .error // "API请求失败"' 2>/dev/null || echo "$RESPONSE")"
      echo "调试信息: 尝试发送到 http://localhost:$PORT/v1/chat/completions"
      echo "消息内容: $MESSAGES"
      exit 1
    fi
    
    # 提取助手回复
    ASSISTANT_REPLY=$(echo "$RESPONSE" | jq -r '.choices[0].message.content' 2>/dev/null)
    
    # 显示助手回复
    echo -e "用户: $USER_PROMPT\n\n助手: $ASSISTANT_REPLY\n"
    
    # 添加助手回复到消息数组
    MESSAGES=$(echo "$MESSAGES" | jq --arg content "$ASSISTANT_REPLY" \
      '. + [{"role": "assistant", "content": $content}]')
  fi

  echo "开始与 $MODEL_NAME 聊天 (输入 'exit' 或 'quit' 退出)"
  echo "---------------------------------------------"
  
  # 聊天循环
  while true; do
    # 提示用户输入
    echo -n "用户: "
    read -r USER_INPUT
    
    # 检查退出命令
    if [[ "$USER_INPUT" == "exit" || "$USER_INPUT" == "quit" ]]; then
      echo "聊天结束"
      exit 0
    fi
    
    # 添加用户消息到消息数组
    MESSAGES=$(echo "$MESSAGES" | jq --arg content "$USER_INPUT" \
      '. + [{"role": "user", "content": $content}]')
    
    # 打印调试信息
    # echo "发送消息: $MESSAGES"
    
    # 发送请求到API
    RESPONSE=$(curl -s -X POST "http://localhost:$PORT/v1/chat/completions" \
      -H "Authorization: Bearer $API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "'"$MODEL_NAME"'",
        "messages": '"$MESSAGES"',
        "temperature": '"$TEMPERATURE"'
      }')
    
    # 检查错误
    if [[ "$RESPONSE" == *"error"* || -z "$RESPONSE" ]]; then
      echo "错误: $(echo "$RESPONSE" | jq -r '.error.message // .error // "API请求失败"' 2>/dev/null || echo "$RESPONSE")"
      echo "调试信息: 尝试发送到 http://localhost:$PORT/v1/chat/completions"
      echo "消息内容: $MESSAGES"
      exit 1
    fi
    
    # 提取助手回复
    ASSISTANT_REPLY=$(echo "$RESPONSE" | jq -r '.choices[0].message.content' 2>/dev/null)
    
    # 显示助手回复
    echo -e "\n助手: $ASSISTANT_REPLY\n"
    
    # 添加助手回复到消息数组
    MESSAGES=$(echo "$MESSAGES" | jq --arg content "$ASSISTANT_REPLY" \
      '. + [{"role": "assistant", "content": $content}]')
  done
  
  exit 0
fi



# 如果GPU_ID是auto，则自动选择GPU
if [[ "$GPU_ID" == "auto" ]]; then
  selected_gpu=$(auto_select_gpu)
  if [ $? -ne 0 ] || [ -z "$selected_gpu" ]; then
    echo "自动选择GPU失败，脚本退出"
    exit 1
  fi
  GPU_ID="$selected_gpu"
fi

echo "正在使用以下配置:"
echo "conda环境: $ENV_NAME"
echo "GPU ID: $GPU_ID"
echo "模型名称: $MODEL_NAME"
echo "API密钥: $API_KEY"
echo "端口号: $PORT"
echo "最大模型长度: ${MAX_MODEL_LEN:-不限制}"
echo "GPU使用率: $GPU_UTIL"
echo "禁用function call: $DISABLE_FUNCTION_CALL"
if [ -n "$TIMEOUT_MINUTES" ] && [ "$TIMEOUT_MINUTES" -gt 0 ]; then
  echo "超时时间: ${TIMEOUT_MINUTES}分钟"
fi

source ~/miniconda3/etc/profile.d/conda.sh || source ~/anaconda3/etc/profile.d/conda.sh
conda activate $ENV_NAME

export CUDA_VISIBLE_DEVICES="$GPU_ID"
export TRANSFORMERS_OFFLINE="1"
export HF_HUB_OFFLINE="1"

CMD="vllm serve \"$MODEL_NAME\" --port $PORT --api-key $API_KEY --gpu-memory-utilization $GPU_UTIL"

if [ -n "$MAX_MODEL_LEN" ]; then
  CMD="$CMD --max-model-len $MAX_MODEL_LEN"
fi

if [ "$DISABLE_FUNCTION_CALL" = false ]; then
  CMD="$CMD --enable-auto-tool-choice --tool-call-parser hermes"
fi

if [ -n "$VLLM_EXTRA_ARGS" ]; then
  CMD="$CMD $VLLM_EXTRA_ARGS"
fi

# 构建并执行vllm命令
echo "执行命令: $CMD"

# 如果设置了超时，启动后台监控进程
if [ -n "$TIMEOUT_MINUTES" ] && [ "$TIMEOUT_MINUTES" -gt 0 ]; then
  echo "启动超时监控进程（${TIMEOUT_MINUTES}分钟后自动退出）..."
  # 在后台启动监控进程
  nohup bash -c "
    # 等待vllm服务启动
    echo '等待vllm服务启动...'
    for i in {1..60}; do
      if ss -tuln 2>/dev/null | grep -q ':$PORT ' || netstat -tuln 2>/dev/null | grep -q ':$PORT '; then
        echo 'vllm服务已启动，开始监控'
        break
      fi
      sleep 1
    done
    
    # 导入并执行监控函数
    $(declare -f monitor_timeout)
    monitor_timeout '$PORT' '$TIMEOUT_MINUTES'
  " > /tmp/ezvllm_monitor_${PORT}.log 2>&1 &
  
  MONITOR_PID=$!
  echo "超时监控进程已启动 (PID: $MONITOR_PID)"
  echo "监控日志: /tmp/ezvllm_monitor_${PORT}.log"
  echo "超时日志: /tmp/ezvllm_timeout_${PORT}.log"
fi

# 启动vllm服务
eval $CMD

# 错误处理和清理
vllm_exit_code=$?
cleanup_monitor
if [ $vllm_exit_code -ne 0 ]; then
  echo "Error running vllm"
  exit 1
fi